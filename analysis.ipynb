{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb46128-ef8a-47f0-9de0-f4a04909b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import sh\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import express as px\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from statsmodels.stats import multitest\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "config = {\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png', # one of png, svg, jpeg, webp\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5c89f6-bdab-4502-a8ce-2c675179a937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_rscript(r_script_contents:list, r_script_data: pd.DataFrame, replace_name: list):\n",
    "    with tempfile.NamedTemporaryFile() as datafile:\n",
    "        repwith = datafile.name\n",
    "        r_script_contents = [line.replace(replace_name,repwith) for line in r_script_contents]\n",
    "        r_script_data.to_csv(datafile, sep='\\t')\n",
    "        with tempfile.NamedTemporaryFile() as scriptfile:\n",
    "            scriptfile.write('\\n'.join(r_script_contents).encode('utf-8'))\n",
    "            scriptfile.flush()\n",
    "            try:\n",
    "                sh.Rscript(scriptfile.name)\n",
    "            except Exception as e:\n",
    "                print('Error while running R script!')\n",
    "                raise e\n",
    "            with open(datafile.name, \"r\") as f:\n",
    "                out = f.read().split('\\n')\n",
    "                out = [o.split('\\t')[1:] for o in out[1:] if len(o)>0] # skip empty rows\n",
    "    script_output_df = pd.DataFrame(data = out)\n",
    "    script_output_df = script_output_df.replace('NA',np.nan).replace('',np.nan).astype(float)\n",
    "    script_output_df.columns = r_script_data.columns # Restore columns and index in case R renames anything from either.\n",
    "    script_output_df.index = r_script_data.index\n",
    "    return script_output_df\n",
    "\n",
    "def impute_qrilc(dataframe: pd.DataFrame, random_seed: int = 12) -> pd.DataFrame:\n",
    "    tempname: uuid.UUID = str(uuid.uuid4())\n",
    "    script: list = [\n",
    "        'library(\"imputeLCMD\")',\n",
    "        f'set.seed({random_seed})',\n",
    "        f'df <- read.csv(\"{tempname}\",sep=\"\\\\t\",row.names=1)',\n",
    "        f'write.table(data.frame(impute.QRILC(df,tune.sigma=1)[1]),file=\"{tempname}\",sep=\"\\\\t\")'\n",
    "    ]\n",
    "    return run_rscript(script, dataframe, tempname)\n",
    "\n",
    "def filter_missing(data_table: pd.DataFrame, sample_groups: dict, threshold: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"Discards rows with more than threshold percent of missing values in all sample groups\"\"\"\n",
    "    threshold: float = float(threshold)/100\n",
    "    keeps: list = []\n",
    "    for _, row in data_table.iterrows():\n",
    "        keep: bool = False\n",
    "        for _, sample_columns in sample_groups.items():\n",
    "            keep = keep | (row[sample_columns].notna().sum()\n",
    "                           >= ceil(threshold*len(sample_columns)))\n",
    "            if keep:\n",
    "                break\n",
    "        keeps.append(keep)\n",
    "    return data_table[keeps].copy()\n",
    "\n",
    "def count_per_sample(data_table: pd.DataFrame, rev_sample_groups: dict) -> pd.Series:\n",
    "    \"\"\"Counts non-zero values per sample (sample names from rev_sample_groups.keys()) and returns a series with sample names in index and counts as values.\"\"\"\n",
    "    index: list = list(rev_sample_groups.keys())\n",
    "    retser: pd.Series = pd.Series(\n",
    "        index=index,\n",
    "        data=[data_table[i].notna().sum() for i in index]\n",
    "    )\n",
    "    return retser\n",
    "\n",
    "def median_normalize(data_frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Median-normalizes a dataframe by dividing each column by its median.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The dataframe to median-normalize.\n",
    "        Each column represents a sample, and each row represents a measurement.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The median-normalized dataframe.\n",
    "    \"\"\"\n",
    "    # Calculating the medians prior to looping is about 2-3 times more efficient,\n",
    "    # than calculating the median of each column inside of the loop.\n",
    "    medians: pd.Series = data_frame.median(axis=0)\n",
    "    mean_of_medians: float = medians.mean()\n",
    "    newdf: pd.DataFrame = pd.DataFrame(index=data_frame.index)\n",
    "    for col in data_frame.columns:\n",
    "        newdf[col] = (data_frame[col] / medians[col]) * mean_of_medians\n",
    "    return newdf \n",
    "\n",
    "def differential(data_table: pd.DataFrame, sample_groups: dict, comparisons: list, adj_p_thr: float = 0.01, fc_thr:float = 1.0) -> pd.DataFrame:\n",
    "    sig_data: list = []\n",
    "    for sample, control in comparisons:\n",
    "        sample_columns: list = sample_groups[sample]\n",
    "        control_columns: list = sample_groups[control]\n",
    "        log2_fold_change: pd.Series = data_table[sample_columns].mean(\n",
    "            axis=1) - data_table[control_columns].mean(axis=1)\n",
    "        sample_mean_val: pd.Series = data_table[sample_columns].mean(axis=1)\n",
    "        control_mean_val: pd.Series = data_table[control_columns].mean(axis=1)\n",
    "        # Calculate the p-value for each protein using a two-sample t-test\n",
    "        p_value: float = data_table.apply(lambda x: ttest_ind(x[sample_columns], x[control_columns])[1], axis=1)\n",
    "\n",
    "        # Adjust the p-values for multiple testing using the Benjamini-Hochberg correction method\n",
    "        _: Any\n",
    "        p_value_adj: np.ndarray\n",
    "        _, p_value_adj, _, _ = multitest.multipletests(p_value, method='fdr_bh')\n",
    "\n",
    "        # Create a new dataframe containing the fold change and adjusted p-value for each protein\n",
    "        result: pd.DataFrame = pd.DataFrame(\n",
    "            {\n",
    "                'fold_change': log2_fold_change, \n",
    "                'p_value_adj': p_value_adj,\n",
    "                'p_value_adj_neg_log10': -np.log10(p_value_adj),\n",
    "                'p_value': p_value,\n",
    "                'sample_mean_value': sample_mean_val,\n",
    "                'control_mean_value': control_mean_val})\n",
    "        \n",
    "        result['Name'] = data_table.index.values\n",
    "        result['Sample'] = sample\n",
    "        result['Control'] = control\n",
    "        result['Significant'] = ((result['p_value_adj']<adj_p_thr) & (result['fold_change'].abs() > fc_thr))\n",
    "        result.sort_values(by='Significant',ascending=True,inplace=True)\n",
    "        sig_data.append(result)\n",
    "        \n",
    "    return pd.concat(sig_data,ignore_index=True)[\n",
    "        ['Sample',\n",
    "         'Control',\n",
    "         'Name',\n",
    "         'Significant',\n",
    "         'fold_change',\n",
    "         'p_value',\n",
    "         'p_value_adj',\n",
    "         'p_value_adj_neg_log10',\n",
    "         'sample_mean_value',\n",
    "         'control_mean_value'\n",
    "         ]]\n",
    "\n",
    "def volcano_plot(\n",
    "    data_table, title: str = None, fc_axis_min_max: float = 2, highlight_only: list = None,\n",
    "    adj_p_threshold: float = 0.01, fc_threshold: float = 1.0\n",
    ") -> tuple:\n",
    "    \"\"\"Draws a Volcano plot of the given data_table\n",
    "\n",
    "    :param data_table: data table from stats.differential. Should only contain one comparison.\n",
    "    :param title: Figure title\n",
    "    :param fc_axis_min_max: minimum for the maximum value of fold change axis. Default of 2 is used to keep the plot from becoming ridiculously narrow\n",
    "    :param adj_p_threshold: threshold of significance for the calculated adjusted p value (Default 0.01)\n",
    "    :param fc_threshold: threshold of significance for the log2 fold change. Proteins with fold change of <-fc_threshold or >fc_threshold are considered significant (Default 1)\n",
    "    :param highlight_only: only highlight significant ones that are also in this list\n",
    "\n",
    "    :returns: volcano_plot: go.Figure\n",
    "    \"\"\"\n",
    "\n",
    "    data_table['Highlight'] = [row['Name'] if row['Significant'] else '' for _, row in data_table.iterrows()]\n",
    "    fig: go.Figure = px.scatter(\n",
    "        data_table,\n",
    "        x='fold_change',\n",
    "        y='p_value_adj_neg_log10',\n",
    "        title=title,\n",
    "        color='Significant',\n",
    "        text='Highlight',\n",
    "        height=800,\n",
    "        width=800,\n",
    "        render_mode='svg',\n",
    "        hover_data=['Name','Significant','p_value_adj_neg_log10','fold_change']\n",
    "    )\n",
    "\n",
    "    # Set yaxis properties\n",
    "    p_thresh_val: float = -np.log10(adj_p_threshold)\n",
    "    pmax: float = max(\n",
    "        data_table['p_value_adj_neg_log10'].max(), p_thresh_val)+0.5\n",
    "    fig.update_yaxes(title_text='-log10 (q-value)', range=[0, pmax])\n",
    "    # Set the x-axis properties\n",
    "    fcrange: float = max(abs(data_table['fold_change']).max(), fc_threshold)\n",
    "    if fcrange < fc_axis_min_max:\n",
    "        fcrange = fc_axis_min_max\n",
    "    fcrange += 0.25\n",
    "    fig.update_xaxes(title_text='Log2 fold change', range=[-fcrange, fcrange])\n",
    "    # Add vertical lines indicating the significance thresholds\n",
    "    fig.add_shape(type='line', x0=-fc_threshold, y0=0, x1=-\n",
    "                  fc_threshold, y1=pmax, line=dict(width=2, dash='dot'))\n",
    "    fig.add_shape(type='line', x0=fc_threshold, y0=0,\n",
    "                  x1=fc_threshold, y1=pmax, line=dict(width=2, dash='dot'))\n",
    "    # And horizontal line:\n",
    "    fig.add_shape(type='line', x0=-fcrange, y0=p_thresh_val,\n",
    "                  x1=fcrange, y1=p_thresh_val, line=dict(width=2, dash='dot'))\n",
    "\n",
    "    # Return the plot\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409d7952-ba5e-4b45-b8a7-b81b4c44f83b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_table = pd.read_csv('example_report.pg_matrix.tsv',sep='\\t',index_col = 'Protein.Group')\n",
    "sample_table = pd.read_csv('example_sample_table.tsv',sep='\\t')\n",
    "sample_groups = {}\n",
    "for _,row in sample_table.iterrows():\n",
    "    sg = row['Sample group']\n",
    "    if sg not in sample_groups:\n",
    "        sample_groups[sg] = []\n",
    "    sample_groups[sg].append(row['Sample name'])\n",
    "    \n",
    "sample_groups_rev = {}\n",
    "for samplegroup,v in sample_groups.items():\n",
    "    for samplename in v:\n",
    "        sample_groups_rev[samplename] = samplegroup\n",
    "data_table.drop(columns=[c for c in data_table.columns if c not in sample_groups_rev],inplace=True)\n",
    "data_table = filter_missing(data_table, sample_groups)\n",
    "data_table = np.log2(data_table)\n",
    "data_table = median_normalize(data_table)\n",
    "data_table = impute_qrilc(data_table)\n",
    "data_table.to_csv('Fully processed data.tsv',sep='\\t')\n",
    "\n",
    "comparisons = []\n",
    "with open('example_comparisons.tsv') as fil:\n",
    "    for line in fil:\n",
    "        comparisons.append(line.strip().split('\\t'))\n",
    "comparisons = [c for c in comparisons if ((c[0] in sample_groups) and (c[1] in sample_groups))]\n",
    "    \n",
    "fc_thr = 1\n",
    "p_thr = 0.01\n",
    "significant_data: pd.DataFrame = differential(\n",
    "    data_table, sample_groups, comparisons, fc_thr=fc_thr, adj_p_thr=p_thr)\n",
    "significant_data.to_csv('Produced comparisons.tsv',sep='\\t',index=False)\n",
    "\n",
    "for _, row in significant_data[['Sample', 'Control']].drop_duplicates().iterrows():\n",
    "    sample: str = row['Sample']\n",
    "    control: str = row['Control']\n",
    "    volcano_plot(\n",
    "        significant_data[(significant_data['Sample'] == sample) & (\n",
    "            significant_data['Control'] == control)],\n",
    "        adj_p_threshold=p_thr, fc_threshold=fc_thr\n",
    "    ).write_html(f'Volcano plot {sample} vs {control}',config=config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd59c62-eba1-4807-ba94-97be7ce3199d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
